---
title: "p8105_hw2_KAB2310"
author: "Kamiah Brown"
date: "2024-10-01"
output: github_document
---
## This is my submission for Homework 5.

### Set up 
```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(broom)
```

# Question 1
#### Function 
```{r}
bday_sim = function(n) {
  sample = sample(1:365, size = n, replace = TRUE)
duplicates = length(unique(sample)) < n
return(duplicates)
}

bday_sim(7)
```

```{r}
#### Running function 1000 times for each group size between 2 and 50
bday_sim = expand_grid(
    iter = 1:10000,
    n = 2:50) |>
  mutate(res = map_lgl(n, bday_sim)) |> 
  group_by(n) |> 
  summarize(
    prob = mean(res)
  )
```

#### Probability as a function (Shared Birthday) of group size
```{r}
bday_sim |>
  ggplot(aes(x = n, y = prob)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Probability of Shared Birthday vs Group",
    x = "Group Size",
    y = "Probability"
  ) +
  theme_minimal()
```

### Comments
The plot demonstrates that as the group size increases, the probability of at least two people sharing a birthday rises quickly at first and then levels off as it approaches 1, highlighting a nonlinear relationship. While smaller groups show a rapid increase in the likelihood of shared birthdays, the rate of increases slows signficantly for larger group sizes (beyond 30), where the probability is approaching 1.

# Question 2 
```{r}
n = 30
sigma = 5

sim_power = function(mu){
  
  tibble(
    x = rnorm(n, mu, sigma)) |> 
      summarize(
        tidy(t.test(x, mu = 0, conf.level = 0.95))) |> 
    select(estimate, p.value)
  
}

# Generate 5000 datasets from the model
sim_result = expand_grid(
  mu = 0:6,
  iter = 1:5000) |> 
  mutate(samp_res = map(mu, sim_power)) |> 
  unnest(samp_res)

```
#### plot showing the proportion of times the null was rejected 
```{r}
sim_result |> 
  group_by(mu) |> 
  summarize(
    power = mean(p.value < 0.05)
  ) |> 
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_line()
```

### Comments
When the effect size, mu, increases, the power of the test also increases. This means that the likelihood of correctly rejecting the null hypothesis rises as mu deviates further from 0. 


#### Plot showing the average estimate of mu and an overlay on the graph showing the average estimate of mu only in samples for which the null was rejected. 
```{r}
df1 = sim_result |> 
  group_by(mu) |> 
  summarize(avg = mean(estimate))  |> 
  mutate(category = "true")
```

```{r}
df2 = sim_result |> 
  filter(p.value < 0.05) |> 
  group_by(mu) |> 
  summarize(avg = mean(estimate)) |> 
  mutate(category = "rejected")

#Combining data frames
df <- rbind(df1, df2)

#Plot 2
ggplot(df, aes(x = mu, y = avg, color = category)) +
  geom_point() +  
  geom_line() +  
  labs(
    title = "Average Estimate by Mu",
    x = "Mu",
    y = "Average Estimate",
    color = "Category"
  ) +
  theme_minimal()
```
### Comments 
